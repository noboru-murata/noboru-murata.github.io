<!DOCTYPE html>
<html lang="en">
    <head>
        <meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="ie=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="author" content="[Noboru Murata]">
<meta name="description" content="In statistical machine learning, we consider the problem of inferring the probability structure behind data from a relatively small number of examples. The key is how to model the probability structure that generates the data and how to efficiently solve the unknown parameters.
We consider the properties of various learning machines, the dynamics of optimization, and the statistical properties of the estimated parameters from the standpoint of mathematical science.
Universality of Multi-Layer Perceptron It has been proved from various points of view that the neural network is a universal function approximator that can approximate arbitrary nonlinear functions sufficiently well." />
<meta name="keywords" content="" />
<meta name="robots" content="noodp" />
<meta name="theme-color" content="" />
<link rel="canonical" href="https://noboru-murata.github.io/research/machine-learning/" />


    <title>
        
            Statistical Machine Learning :: Noboru Murata  — Faculty of Science and Engineering, Waseda University
        
    </title>





<link rel="stylesheet" href="/main.b78c3be9451dc4ca61ca377f3dc2cf2e6345a44c2bae46216a322ef366daa399.css" integrity="sha256-t4w76UUdxMphyjd/PcLPLmNFpEwrrkYhajIu82bao5k=">



    <link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png">
    <link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png">
    <link rel="manifest" href="/site.webmanifest">
    <link rel="mask-icon" href="/safari-pinned-tab.svg" color="">
    <link rel="shortcut icon" href="/favicon.ico">
    <meta name="msapplication-TileColor" content="">


<meta itemprop="name" content="Statistical Machine Learning">
<meta itemprop="description" content="In statistical machine learning, we consider the problem of inferring the probability structure behind data from a relatively small number of examples. The key is how to model the probability structure that generates the data and how to efficiently solve the unknown parameters.
We consider the properties of various learning machines, the dynamics of optimization, and the statistical properties of the estimated parameters from the standpoint of mathematical science.
Universality of Multi-Layer Perceptron It has been proved from various points of view that the neural network is a universal function approximator that can approximate arbitrary nonlinear functions sufficiently well."><meta itemprop="datePublished" content="2021-08-19T00:00:00+09:00" />
<meta itemprop="dateModified" content="2021-08-19T00:00:00+09:00" />
<meta itemprop="wordCount" content="343"><meta itemprop="image" content="https://noboru-murata.github.io/"/>
<meta itemprop="keywords" content="" />
<meta name="twitter:card" content="summary_large_image"/>
<meta name="twitter:image" content="https://noboru-murata.github.io/"/>

<meta name="twitter:title" content="Statistical Machine Learning"/>
<meta name="twitter:description" content="In statistical machine learning, we consider the problem of inferring the probability structure behind data from a relatively small number of examples. The key is how to model the probability structure that generates the data and how to efficiently solve the unknown parameters.
We consider the properties of various learning machines, the dynamics of optimization, and the statistical properties of the estimated parameters from the standpoint of mathematical science.
Universality of Multi-Layer Perceptron It has been proved from various points of view that the neural network is a universal function approximator that can approximate arbitrary nonlinear functions sufficiently well."/>



    <meta property="og:title" content="Statistical Machine Learning" />
<meta property="og:description" content="In statistical machine learning, we consider the problem of inferring the probability structure behind data from a relatively small number of examples. The key is how to model the probability structure that generates the data and how to efficiently solve the unknown parameters.
We consider the properties of various learning machines, the dynamics of optimization, and the statistical properties of the estimated parameters from the standpoint of mathematical science.
Universality of Multi-Layer Perceptron It has been proved from various points of view that the neural network is a universal function approximator that can approximate arbitrary nonlinear functions sufficiently well." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://noboru-murata.github.io/research/machine-learning/" /><meta property="og:image" content="https://noboru-murata.github.io/"/><meta property="article:section" content="research" />
<meta property="article:published_time" content="2021-08-19T00:00:00+09:00" />
<meta property="article:modified_time" content="2021-08-19T00:00:00+09:00" />






    <meta property="article:published_time" content="2021-08-19 00:00:00 &#43;0900 JST" />











    </head>

    
        <body>
    
    
        <div class="container">
            <header class="header">
    <span class="header__inner">
        <a href="https://www.murata.eb.waseda.ac.jp/" style="text-decoration: none;">
    <div class="logo">
        
            <span class="logo__mark">&gt;</span>
            <span class="logo__text ">
                cd ~</span>
            <span class="logo__cursor" style=
                  "
                   
                   ">
            </span>
        
    </div>
</a>


        <span class="header__right">
            
                <nav class="menu">
    <ul class="menu__inner"><li><a href="/research">Research</a></li><li><a href="/publications">Publications</a></li><li><a href="/lectures">Lectures</a></li><li><a href="/vitae">Vitae</a></li><li><a href="/about">about</a></li>
    </ul>
</nav>

                <span class="menu-trigger">
                    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24">
                        <path d="M0 0h24v24H0z" fill="none"/>
                        <path d="M3 18h18v-2H3v2zm0-5h18v-2H3v2zm0-7v2h18V6H3z"/>
                    </svg>
                </span>
            
                <span class="theme-toggle not-selectable"><svg class="theme-toggler" width="24" height="24" viewBox="0 0 48 48" fill="none" xmlns="http://www.w3.org/2000/svg">
   <path d="M22 41C32.4934 41 41 32.4934 41 22C41 11.5066 32.4934 3 22
   3C11.5066 3 3 11.5066 3 22C3 32.4934 11.5066 41 22 41ZM7 22C7
   13.7157 13.7157 7 22 7V37C13.7157 37 7 30.2843 7 22Z"/>
 </svg></span>
        </span>
    </span>
</header>


            <div class="content">
                
    <main class="post">

        <div class="post-info">
            
            </p>
        </div>

        <article>
            <h2 class="post-title"><a href="https://noboru-murata.github.io/research/machine-learning/">Statistical Machine Learning</a></h2>

            
            
            

            <div class="post-content">
                <p>In statistical machine learning, we consider the problem of inferring
the probability structure behind data from a relatively small number
of examples. The key is how to model the probability structure that
generates the data and how to efficiently solve the unknown
parameters.</p>
<p>We consider the properties of various learning machines, the dynamics
of optimization, and the statistical properties of the estimated
parameters from the standpoint of mathematical science.</p>
<h2 id="universality-of-multi-layer-perceptron">Universality of Multi-Layer Perceptron</h2>
<p>It has been proved from various points of view that the neural network
is a universal function approximator that can approximate arbitrary
nonlinear functions sufficiently well. We clarify the class of
functions that can be represented by the neural network based on the
integral representation (Ridgelet transform), and investigate the
relationship between the accuracy of approximation by finite sums and
the integral representation.</p>

    <img src="/pdfs/neural-network.gif"  alt="Universality of Neural Network"  class="center"  style="border-radius: 8px;"  />


<p><a href="/pdfs/neural-network.pdf">[ slide ]​</a></p>
<blockquote>
<p>Murata, N.:
&ldquo;An integral representation of functions using three-layered networks and their approximation bounds&rdquo;,
<em>Neural Networks</em>,
Volume 9, Issue 6, August 1996, Pages 947-956.
<a href="https://doi.org/10.1016/0893-6080(96)00000-7">https://doi.org/10.1016/0893-6080(96)00000-7</a></p>
</blockquote>
<h2 id="change-point-detection-in-a-sequence-of-bags-of-data">Change-Point Detection in a Sequence of Bags-of-Data</h2>
<p>Change-point detection is an important engineering problem, and
various methods have been proposed. Many existing methods assume that
each data point observed at each time step is a single
multi-dimensional vector, but to make them applicable to a wider class
of problems, we propose a non-parametric and computationally efficient
method. First, the underlying distribution behind each bag-of-data is
estimated and embedded in the metric space with earth mover&rsquo;s
distance. Then, using the distance-based information estimator, we
evaluate how the sequence of bags-of-data varies in the metric space
to derive a change-point score. A procedure is also incorporated to
adaptively determine the timing of alarms by calculating confidence
intervals for the change-point scores at each time step by means of
Bayesian bootstrap. This makes it possible to avoid false alarms in
noisy situations and to detect changes of various magnitudes.</p>

    <img src="/pdfs/change-point.gif"  alt="Change-Point Detection in a Sequence of Bags-of-Data"  class="center"  style="border-radius: 8px;"  />


<p><a href="/pdfs/change-point.pdf">[ slide ]​</a></p>
<blockquote>
<p>Koshijima, K., Hino, H. and Murata, N.:
&ldquo;Change-Point Detection in a Sequence of Bags-of-Data&rdquo;,
<em>IEEE Transactions on Knowledge and Data Engineering</em>,
Volume 27, Number 10, October 2015, Pages 2632-2644.
<a href="https://doi.org/10.1109/TKDE.2015.2426693">https://doi.org/10.1109/TKDE.2015.2426693</a></p>
</blockquote>
<hr>

    <img src="/images/logo.png"  alt="to be continued"  class="right"  style="border-radius: 8px;"  />



            </div>
        </article>

        <hr />

        <div class="post-info">
            
            
  		</div>
    </main>

            </div>

            
                <footer class="footer">
    
    <div class="footer__inner">
        <div class="footer__content">
            <span>&copy; 2023</span>
            <span><a href="https://noboru-murata.github.io/">Noboru Murata</a></span>
            <span><a href="https://creativecommons.org/licenses/by-nc/4.0/" target="_blank" rel="noopener">CC BY-NC 4.0</a></span>
            
            
        </div>
    </div>
    
    
    <div class="footer__inner">
        <div class="footer__content">
            <span>Powered by <a href="http://gohugo.io">Hugo</a></span><span>Made with &#10084; by <a href="https://github.com/rhazdon">Djordje Atlialp</a></span>
        </div>
    </div>
    
</footer>

            
        </div>

        



<script type="text/javascript" src="/bundle.min.3285bac296fd592c2fed6541b76ae71f22e191263130d0189838d04cf171402c7d19f9e7781bc4bd8a9f77eec9369860301f4ac8c5b43e9741b2c1997ae2adbd.js" integrity="sha512-MoW6wpb9WSwv7WVBt2rnHyLhkSYxMNAYmDjQTPFxQCx9GfnneBvEvYqfd&#43;7JNphgMB9KyMW0PpdBssGZeuKtvQ=="></script>



    </body>
</html>
